{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilistic Programming with Haskell\n",
    "\n",
    "Siddhart Bath, Simeon Carstens, Matthias Meschede\n",
    "\n",
    "_first published on www.tweag.io/blog_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ":e OverloadedStrings\n",
    ":e ExistentialQuantification\n",
    "\n",
    "import System.Random.MWC (createSystemRandom)\n",
    "import qualified Graphics.Vega.VegaLite as VL\n",
    "import IHaskell.Display.Hvega (vlShow)\n",
    "import Data.Aeson (ToJSON(toJSON), Value)\n",
    "import Data.Aeson (encode)\n",
    "import qualified Data.ByteString.Lazy.Char8 as BL\n",
    "import Data.Text (Text, pack)\n",
    "\n",
    "import Control.Monad (liftM2, replicateM, forM, forM_)\n",
    "import Control.Monad.IO.Class (liftIO)\n",
    "import Data.List (sort)\n",
    "import Control.Monad.Bayes.Class\n",
    "import Control.Monad.Bayes.Sampler\n",
    "import Control.Monad.Bayes.Traced\n",
    "import Control.Monad.Bayes.Weighted\n",
    "import Control.Monad.Bayes.Inference.SMC as SMC\n",
    "import Control.Monad.Bayes.Inference.RMSMC as RMSMC\n",
    "import Control.Monad.Bayes.Sequential\n",
    "import Control.Monad.Bayes.Population\n",
    "import Control.Monad.Bayes.Traced.Static (Traced)\n",
    "import Control.Monad.Bayes.Inference.SMC\n",
    "import Numeric.LinearAlgebra (Matrix, Vector, vector, matrix, dot, (#>), cmap, scalar)\n",
    "\n",
    "import Numeric.Log\n",
    "import Control.Monad.Bayes.Class\n",
    "\n",
    "import Data.List (partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barPlot :: Text -> VL.VLSpec\n",
    "barPlot xName = \n",
    "    let encoding = VL.encoding\n",
    "            . VL.position VL.X [VL.PName xName, VL.PmType VL.Nominal]\n",
    "            . VL.position VL.Y [VL.PName \"binnedData\", VL.PAggregate VL.Count, VL.PmType VL.Quantitative, VL.PAxis [VL.AxTitle \"count\"]]\n",
    "    in VL.asSpec [VL.mark VL.Bar [VL.MOpacity 1.0, VL.MColor \"#a3c6de\"], encoding []]\n",
    "\n",
    "linePlot :: Text -> Text -> VL.VLSpec\n",
    "linePlot xName yName = \n",
    "  let encoding = VL.encoding\n",
    "            . VL.position VL.X [VL.PName xName, VL.PmType VL.Quantitative]\n",
    "            . VL.position VL.Y [VL.PName yName, VL.PmType VL.Quantitative]\n",
    "  in VL.asSpec [VL.mark VL.Line [VL.MColor \"blue\"], encoding []]\n",
    "\n",
    "scatterBlue xName yName (xmin, xmax) (ymin, ymax) =\n",
    "  let encoding = VL.encoding\n",
    "            . VL.position VL.X [VL.PName xName, VL.PmType VL.Quantitative, VL.PScale [VL.SDomain $ VL.DNumbers [xmin, xmax]]]\n",
    "            . VL.position VL.Y [VL.PName yName, VL.PmType VL.Quantitative, VL.PScale [VL.SDomain $ VL.DNumbers [ymin, ymax]]]\n",
    "  in VL.asSpec [VL.mark VL.Circle [VL.MColor \"blue\"], encoding []]\n",
    "  \n",
    "scatterGreen xName yName (xmin, xmax) (ymin, ymax) =\n",
    "  let encoding = VL.encoding\n",
    "            . VL.position VL.X [VL.PName xName, VL.PmType VL.Quantitative, VL.PScale [VL.SDomain $ VL.DNumbers [xmin, xmax]]]\n",
    "            . VL.position VL.Y [VL.PName yName, VL.PmType VL.Quantitative, VL.PScale [VL.SDomain $ VL.DNumbers [ymin, ymax]]]\n",
    "  in VL.asSpec [VL.mark VL.Circle [VL.MColor \"green\"], encoding []]\n",
    "  \n",
    "scatterPlotWithColor :: Text -> Text -> Text -> (Double, Double) -> (Double, Double) -> VL.VLSpec\n",
    "scatterPlotWithColor xName yName zName (xmin, xmax) (ymin, ymax) =\n",
    "  let encoding = VL.encoding\n",
    "            . VL.position VL.X [VL.PName xName, VL.PmType VL.Quantitative, VL.PScale [VL.SDomain $ VL.DNumbers [xmin, xmax]]]\n",
    "            . VL.position VL.Y [VL.PName yName, VL.PmType VL.Quantitative, VL.PScale [VL.SDomain $ VL.DNumbers [ymin, ymax]]]\n",
    "            . VL.color [ VL.MName zName, VL.MmType VL.Quantitative, VL.MScale [VL.SScheme \"blues\" [0.0, 1.0]]]\n",
    "  in VL.asSpec [VL.mark VL.Circle [], encoding []]\n",
    "\n",
    "density2DPlot :: Text -> Text -> (Double, Double) -> (Double, Double) -> VL.VLSpec\n",
    "density2DPlot xName yName (xmin, xmax) (ymin, ymax) = \n",
    "  let encoding = VL.encoding\n",
    "            . VL.position VL.X [VL.PName xName, VL.PBin [VL.Nice False, VL.Steps [0.05, 0.5, 5.0], VL.Extent xmin xmax], VL.PmType VL.Quantitative]\n",
    "            . VL.position VL.Y [VL.PName yName, VL.PBin [VL.Nice False, VL.Steps [0.05, 0.5, 5.0], VL.Extent ymin ymax], VL.PmType VL.Quantitative]\n",
    "            . VL.color [ VL.MAggregate VL.Count, VL.MName \"col\", VL.MmType VL.Quantitative, VL.MScale [VL.SScheme \"blues\" [0.0, 1.0]]]\n",
    "  in VL.asSpec [VL.mark VL.Rect [], encoding []]\n",
    "\n",
    "imagePlot :: Text -> Text -> Text -> VL.VLSpec\n",
    "imagePlot xName yName zName =\n",
    "  let encoding = VL.encoding\n",
    "            . VL.position VL.X [VL.PName xName, VL.PmType VL.Nominal, VL.PAxis [VL.AxGridOpacity 0.1]]\n",
    "            . VL.position VL.Y [VL.PName yName, VL.PmType VL.Nominal, VL.PSort [VL.Descending], VL.PAxis [VL.AxGridOpacity 0.1]]\n",
    "            . VL.fill [ VL.MName zName, VL.MmType VL.Quantitative, VL.MScale [VL.SScheme \"blues\" [0.0, 1.0]]]\n",
    "            . VL.stroke [ VL.MName zName, VL.MmType VL.Quantitative, VL.MScale [VL.SScheme \"blues\" [0.0, 1.0]],\n",
    "                          VL.MLegend [VL.LType VL.GradientLegend]]\n",
    "  in VL.asSpec [VL.mark VL.Rect [], encoding []]\n",
    "  \n",
    "imageFacetPlot :: Text -> Text -> Text -> VL.VLSpec\n",
    "imageFacetPlot xName yName zName =\n",
    "  let encoding = VL.encoding\n",
    "            . VL.position VL.X [VL.PName xName, VL.PmType VL.Ordinal, VL.PAxis [VL.AxGrid False]]\n",
    "            . VL.position VL.Y [VL.PName yName, VL.PmType VL.Ordinal, VL.PSort [VL.Descending], VL.PAxis [VL.AxGrid False]]\n",
    "            . VL.fill [ VL.MName zName, VL.MmType VL.Quantitative, VL.MScale [VL.SScheme \"blues\" [0.0, 1.0]], VL.MLegend [VL.LOrient VL.LOBottom]]\n",
    "            . VL.stroke [ VL.MName zName, VL.MmType VL.Quantitative, VL.MScale [VL.SScheme \"blues\" [0.0, 1.0]],\n",
    "                          VL.MLegend [VL.LOrient VL.LOBottom, VL.LDirection VL.Horizontal, VL.LType VL.GradientLegend]]\n",
    "  in VL.asSpec [VL.mark VL.Rect [], encoding [], VL.width 200,  VL.height 100]\n",
    "\n",
    "data SpecGrid = H [[VL.VLSpec]] | V [[VL.VLSpec]] | L [VL.VLSpec] | S VL.VLSpec | F (Text, Int, VL.VLSpec)\n",
    "\n",
    "data InputData = Cols [(Text, VL.DataValues)]\n",
    "               | File FilePath\n",
    "\n",
    "plot :: (Double, Double) -> SpecGrid -> InputData -> VL.VegaLite\n",
    "plot (figw,figh) specGrid dataPoints =\n",
    "    let description = VL.description \"Plot\"\n",
    "        dat' = case dataPoints of\n",
    "            Cols cols -> foldl (.) (VL.dataFromColumns []) (map (uncurry VL.dataColumn) cols) []\n",
    "            File fp -> VL.dataFromSource (pack fp) []\n",
    "        configure = VL.configure\n",
    "            . VL.configuration (VL.Axis\n",
    "                                        [ VL.Domain False,\n",
    "                                          VL.LabelColor \"#7F7F7F\",\n",
    "                                          VL.LabelPadding 4,\n",
    "                                          VL.TickColor \"#7F7F7F\",\n",
    "                                          VL.TickSize 5.67,\n",
    "                                          VL.Grid True,\n",
    "                                          VL.GridColor \"#FFFFFF\"\n",
    "                                          ])\n",
    "        spec = case specGrid of\n",
    "            S s -> VL.layer [s]\n",
    "            L ls -> VL.layer ls\n",
    "            H lss -> VL.hConcat (map (VL.asSpec . (:[]) . VL.layer) lss)\n",
    "            V lss -> VL.vConcat (map (VL.asSpec . (:[]) . VL.layer) lss)\n",
    "            F (_, _, s) -> VL.specification s\n",
    "        facet = case specGrid of\n",
    "            F (field, nColumns, _) -> [VL.columns $ fromIntegral nColumns, VL.facetFlow [VL.FName field, VL.FmType VL.Nominal]]\n",
    "            _   -> [VL.width figw,  VL.height figh]\n",
    "    in VL.toVegaLite $ [VL.background \"#f9f9f9\", configure [], description, dat', spec] ++ facet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this blog post series, we're going to lead you through Bayesian modeling in Haskell with the [`monad-bayes`](https://github.com/adscib/monad-bayes/tree/647ba7cb5a98ae028600f3d828828616891b40fb) library.\n",
    "We start this series gradually with some simple binary models, move next to linear regression, and finish by building a simple neural network that we \"train\" with a Metropolis-Hastings sampler.\n",
    "You don't need any prior knowledge of Bayesian modeling to understand and learn from these posts—and we keep the code simple and understandable for Haskell newcomers.\n",
    "\n",
    "Want to make this post interactive? Try our [notebook version](https://gist.github.com/MMesch/dee0659e480b572d0b36088a2b08cc57). It includes a Nix shell, the required imports, and some helper routines for plotting. Let's start modeling! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: First Steps\n",
    "\n",
    "### Sampling\n",
    "\n",
    "In this first part of the series, we introduce two fundamental concepts of `monad-bayes`: `sampling` and `scoring`.\n",
    "We examine them based on one of the simplest probabilistic models that we can think of—a model that represents a `True` or `False` choice.\n",
    "You can use it, for example, to describe the answer to a question such as \"Did it rain yesterday?\".\n",
    "\n",
    "The model is parameterized by a boolean `b`, and in this simple case, `b` is also directly the model output.\n",
    "Without additional information, we assign equal probabilities `0.5` to each value that `b` can take (50% `True`, 50% `False`).\n",
    "In other words, we get the model parameter `b` from a discrete uniform [prior](https://en.wikipedia.org/wiki/Prior_probability) distribution.\n",
    "\n",
    "Let's see how the model looks like in the`monad-bayes`library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 :: MonadSample m => m Bool\n",
    "model1 = do\n",
    "    b <- uniformD [False, True]\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `monad-bayes` a model is expressed through the typeclass `MonadSample`.\n",
    "The `MonadSample` typeclass provides a function `random` to our `model1` that returns a random sample from it.\n",
    "The type of the sample itself is set to `Bool` in our case.\n",
    "\n",
    "We define our model by binding together other basic `MonadSample` models.\n",
    "In this case, for example, we build our model from the `uniformD` distribution that is provided by `monad-bayes`\n",
    "The model, that is the chain of actions that are bound together in _MonadSample_, is not executed until we start sampling from the model.\n",
    "Once we sample, the resulting chain of actions that is executed is simple:\n",
    "draw `b` from a discrete uniform distribution (_uniformD_) and then return its value.\n",
    "\n",
    "Sampling can be executed with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleIOfixed model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get a list of samples with Haskell's `replicateM` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 1000\n",
    "samples <- sampleIOfixed $ replicateM nsamples model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then plot the result afterwards with [Vega-Lite](https://github.com/vega/vega-lite#readme) (module `VL`).\n",
    "You can find our custom plotting functions for Vega-Lite in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlShow $ plot (200, 100) (L [barPlot \"b\"]) (Cols [(\"b\", VL.Booleans samples)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, so good: we now have a model that represents a distribution of `True/False` values and we can draw samples from it.\n",
    "But how can we include observations into this model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "Consider again `model1` as the answer to \"Did it rain yesterday?\".\n",
    "What if we found out \"Yes, it did rain yesterday!\"?\n",
    "To include this new knowledge, we need to update the distribution of the model parameter `b`.\n",
    "\n",
    "In `monad-bayes` the function `score` is responsible for making samples more or less likely—by a factor.\n",
    "Don't worry if you are mystified by this explanation, we'll explain more in a moment.\n",
    "But first check out `model2` that uses `score` to include the observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 :: MonadInfer m => m Bool\n",
    "model2 = do\n",
    "    b <- uniformD [False, True]\n",
    "    score (if b then 1.0 else 0.0)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the new typeclass `MonadInfer` that allows us to use `score` in addition to sampling.\n",
    "Instead of a single operation, the model is now a chain of actions: _sample_, _score_, …\n",
    "\n",
    "Here's a naive idea of how this could work:\n",
    "assume that the representation of the probability distribution of `b` was a list of tuples `[(0.5, True), (0.5, False)]`.\n",
    "We would multiply this distribution with the distribution of my observation \"Yes, it did rain yesterday!\", that is with `[(1, True), (0, False)]`.\n",
    "Then we would normalize the updated probabilities such that they sum to one, and the job is done.\n",
    "\n",
    "So are we secretly tracking the probability of all samples—the full distribution—at every step (in the Haskell world a.k.a. some variant of the [_Dist_ monad](http://www.randomhacks.net/files/build-your-own-probability-monads.pdf))?\n",
    "Granted, in the case of a `True`/`False` question this might be a good approach—_but this is not what is happening here for very good reasons_:\n",
    "\n",
    "To update a sample's probability as described above we need to track all samples with their probabilities and run global normalization operations on them.\n",
    "We are essentially running computations with full distributions over all possible values.\n",
    "This quickly becomes intractable because a model can basically be any Haskell function with lots and lots of possible outcomes.\n",
    "\n",
    "`monad-bayes` and similar probabilistic frameworks use an elegant approach that do what we want _without dragging around full distributions_.\n",
    "The trick behind is to approximate the outcome distribution by drawing successive samples from it.\n",
    "It turns out that it is enough to know the _relative probability_ of two samples at a time to do this.\n",
    "The relative probability of the two samples is independent of the probability of other samples—computations on full distributions are thus reduced to computations on samples.\n",
    "With appropriate sampling algorithms ([MCMC](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo)) we can approximate the outcome distribution despite this limited knowledge.\n",
    "It is difficult to overstate the implications:\n",
    "with MCMC we can address all kinds of sampling related problems in a probabilistic manner that would be completely inaccessible otherwise.\n",
    "\n",
    "Let's get back to the `score` function that modifies the probability to pull a certain sample from the distribution.\n",
    "We now understand that it multiplies the _relative probability_ to observe a sample compared to any other with a factor.\n",
    "This means that the sample's probability is left untouched if this factor is `1`.\n",
    "If this factor is `10`, the sample's relative probability is increased ten fold with respect to any other sample.\n",
    "If this factor is `0`, the sample's probability is set to `0`.\n",
    "\n",
    "Here is `model2` expressed in words: (a) draw a sample from `[True, False]` with equal probability,\n",
    "and (b) multiply the relative probability of a sample with value `True` with `1` and of a sample with value `False` with `0`.\n",
    "\n",
    "An appropriate sampler can trace and accumulate the score factor of a sample to compare with the score factor of other samples.\n",
    "The accumulated score factors give us access to the relative probability of the two samples, and then we can use MCMC to start sampling.\n",
    "We won't go into detail here about how tracing and accumulating works or which two samples we are actually comparing.\n",
    "`monad-bayes` provides a few samplers that can go through this process in different ways.\n",
    "We include here the `prior` and the `mh` ([Metropolis-Hastings](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm) sampler) functions before our well known `sampleIOfixed` function to use an MCMC sampler.\n",
    "Hopefully, the general idea became clear enough here. We'll provide more of the details later in this series.\n",
    "\n",
    "The final result looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 1000\n",
    "samples <- sampleIOfixed $ prior $ mh nsamples model2\n",
    "vlShow $ plot (200, 100) (L [barPlot \"b\"]) (Cols [(\"b\", VL.Booleans samples)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voilà, we wrote down a model (answer to \"Did it rain yesterday?\") with an uninformed (uniform) prior, and updated it based on the observation \"It rained yesterday!\".\n",
    "The distribution of parameter `b` after scoring—its posterior distribution—has probability `1` for True and probability `0` for False.\n",
    "The operations that we needed to figure out the posterior distribution were _random_ and _score_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple parameters\n",
    "\n",
    "Let's move onwards to more complex models:\n",
    "What if we considered a model with two parameters?\n",
    "Both parameters are drawn independently from uniform _continuous_ distributions between `-1` and `1`.\n",
    "Again, we want to score this model.\n",
    "This time, we use the function `condition` that is a short form for scoring with `1` or `0` based on a condition.\n",
    "The new model becomes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 :: MonadInfer m => m (Double, Double)\n",
    "model3 = do\n",
    "    b <- uniform (-1) 1\n",
    "    m <- uniform (-1) 1\n",
    "    condition $ (b-m) > 0\n",
    "    return (b, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The principal approach is the same: pick sample `b`, pick sample `m`, modify the joint sample probability based on a condition, and return the values of both samples in a tuple.\n",
    "If we run this through the Metropolis-Hastings sampler, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 5000\n",
    "modelsamples <- sampleIOfixed $ prior $ mh nsamples model3\n",
    "(xValues, yValues) = unzip modelsamples\n",
    "vlShow $ plot (600, 300)\n",
    "              (L [density2DPlot \"b\" \"m\" (-1.1,1.1) (-1.1,1.1)])\n",
    "              (Cols [(\"b\", VL.Numbers xValues), (\"m\", VL.Numbers yValues)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting distribution in the plot above is `0` where `b<m`, and approximately uniform when `b>m`, as we'd expect.\n",
    "You might spot the initial state of the Markov chain as a faint rectangle in the `b<m` region.\n",
    "\n",
    "How about multiple conditions?\n",
    "Remember, we can freely bind operations together so it shouldn't be a problem.\n",
    "This model chains two sampling and two condition operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 :: MonadInfer m => m (Double, Double)\n",
    "model4 = do\n",
    "    b <- uniform (-1) 1\n",
    "    m <- uniform (-1) 1\n",
    "    condition $ (b-m) > 0\n",
    "    condition $ (b+m) > 0\n",
    "    return (b, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it produces the expected result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples = 5000\n",
    "modelsamples <- sampleIOfixed $ prior $ mh nsamples model4\n",
    "(xValues, yValues) = unzip modelsamples\n",
    "vlShow $ plot (600, 300)\n",
    "              (L [density2DPlot \"b\" \"m\" (-1.1,1.1) (-1.1,1.1)])\n",
    "              (Cols [(\"b\", VL.Numbers xValues), (\"m\", VL.Numbers yValues)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "We have seen how we can build models and examine related probability distributions by drawing samples and modifying their relative probabilities with the `score` function.\n",
    "The MCMC approach taken by`monad-bayes`and similar frameworks avoids computations with full distributions, and works with individual samples to enormously simplify life.\n",
    "`monad-bayes`can, therefore, be used to approximate large and complex distributions—something that quickly comes in handy.\n",
    "We can use`monad-bayes`to approximate the distribution of the return values of basically any Haskell function for a given input distribution.\n",
    "This could even be the return values of entire programs.\n",
    "Even better—we can use `score` to infer the input distribution if we have a way of scoring samples based on observations.\n",
    "\n",
    "We hope you enjoyed this first post in our _Probabilistic Programming with monad&#8209;bayes Series_ and learned lots! Now, you're ready to build more general statistical models using these building blocks, and proceed to linear regression in our next post. We hope you join us!\n",
    "\n",
    "part 2 (link to come)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "We use [this GitHub version](https://github.com/adscib/monad-bayes/tree/647ba7cb5a98ae028600f3d828828616891b40fb) of`monad-bayes`in our posts and notebooks since it's neither on Hackage nor Stackage right now. Here are two original articles you may want to check out:\n",
    "\n",
    "* [Practical Probabilistic Programming with Monads](http://mlg.eng.cam.ac.uk/pub/pdf/SciGhaGor15.pdf)\n",
    "* [Functional Programming for Modular Bayesian Inference](http://denotational.co.uk/publications/scibior-kammar-ghahramani-funcitonal-programming-for-modular-bayesian-inference.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This post is a continuation of Tweag's _**Probabilistic Programming with monad‑bayes Series**_. You can find {Part 1 here](https://www.tweag.io/posts/2019-09-20-monad-bayes-1.html).\n",
    "Want to make this post interactive? Try our [notebook version](https://github.com/tweag/blog-resources/tree/master/monad-bayes-series). It includes a Nix shell, the required imports, and some helper routines for plotting. Let's start modeling!\n",
    "\n",
    "### Modeling\n",
    "\n",
    "The lawn is wet, did it rain?\n",
    "The ground moves, is there an earthquake?\n",
    "Prices rise, are we in an economic crisis?\n",
    "Wiggly lines appear on the screen, did a black hole perturb gravity on Earth?\n",
    "Patterns emerge in software [dependency graphs](https://www.tweag.io/posts/2019-02-06-mapping-open-source.html) and [source code](https://www.tweag.io/posts/2019-08-01-codestatistics-umap.html), is this the outcome of a particular development style?\n",
    "Evidence is found in a legal discovery procedure, is anyone guilty of wrongdoing?\n",
    "\n",
    "We continuously make observations similar to \"the lawn is wet\".\n",
    "Such data touches our senses either directly, or indirectly through a measurement device.\n",
    "It is visible, concrete, and therefore unquestioned here—contrary to the invisible and abstract processes that might have generated it.\n",
    "\n",
    "Neither can every process generate this data—\n",
    "earthquakes don't (usually) wet the lawn, black holes don't (yet) influence prices, and legal malpractice doesn't (often) bring about specific source code patterns—\n",
    "nor is there a unique process that can generate it:\n",
    "earthquakes and black holes can both move the ground; sprinklers and rain can wet the lawn equally well.\n",
    "Hence, a process implies data, but data doesn't imply a process.\n",
    "\n",
    "The conclusion is that we can't conclude that a single process is behind the data, but processes aren't indistinguishable either.\n",
    "We can _compare_ them by assessing how likely it is that they generate the data.\n",
    "Bayesian inference and the laws of probability tell us _how_ to make this comparison rationally.\n",
    "\n",
    "Conceptually it is simple:\n",
    "Define a set of processes that we want to compare and prior beliefs in each of them (the _prior distribution_). \n",
    "For each of these processes, describe and compute the probability that it generates the observed data (the _likelihood_).\n",
    "Score each process - that is multiply the prior belief in a process with the likelihood.\n",
    "Renormalize and examine the result, the posterior beliefs in each model (the _posterior distribution_).\n",
    "\n",
    "In this blog post, we walk through this process step by step with [`monad-bayes`](https://github.com/adscib/monad-bayes#readme).\n",
    "First, we set up a _statistical model_ that describes an ensemble of data generation processes.\n",
    "Then, we generate synthetic data with one specific process in this ensemble.\n",
    "From this data, we try to infer which process we have used from the ones that our statistical model describes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Setup\n",
    "\n",
    "The data that we consider are two-dimensional points (x, y).\n",
    "These points could be observations of time and velocity, location and temperature, velocity and acceleration, or any other two continuous variables that we observe.\n",
    "Here is how we can describe such data with Haskell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data Data\n",
    "  = Data\n",
    "      { xValue :: Double,\n",
    "        yValue :: Double\n",
    "      }\n",
    "  deriving (Eq, Show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model that we consider generates data along lines with some Gaussian noise around.\n",
    "This means that the x and y values of our data points cannot take any value, but that `y` can be calculated from `x` with the equation `m*x + b + n`, with parameters `m,b` that are the same for all points and a random, normally-distributed deviation `n` that is independently drawn for each point.\n",
    "In Haskell, the model, i.e., the lines that it describes, can thus be characterized with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data Params\n",
    "  = Params\n",
    "      { slope :: Double,\n",
    "        intercept :: Double,\n",
    "        noiseStd :: Double\n",
    "      }\n",
    "  deriving (Eq, Show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The likelihood, the heart of our model, corresponds to this succinct Haskell function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood :: Params -> Data -> Log Double\n",
    "likelihood (Params m b nStd) (Data x y) = normalPdf (m*x + b) nStd y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It describes the probability (`Log Double`) to observe some data (`Data`) given some model parameters (`Params`).\n",
    "In our case, it's just a Gaussian distribution (`normalPdf`), centered at `m*x + b` for a given `x` and standard deviation `nStd`.\n",
    "That's it—the model definition is unspectacular and short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Model As A Family Of Distributions\n",
    "\n",
    "For a given value of `Params`, `likelihood` provides us with the (log-)probability for a `Data` point.\n",
    "In other words, it describes a probability distribution.\n",
    "We can pick data samples from such a _sampling distribution_—modeling a real-world data generating process.\n",
    "For instance, let's choose the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " params0 = Params {slope=2.3, intercept=(-1.2), noiseStd=2.0} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The associated sampling distribution can then be obtained with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplingDistribution' :: Data -> Double\n",
    "samplingDistribution' = exp . ln . likelihood params0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extra `exp . ln` snippet here is required to extract a `Double` from a `Log Double`, a data type that internally stores the logarithm of a number instead of the actual value.\n",
    "Here is a plot that shows how this 2D sampling distribution looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points1 = [(x, y, samplingDistribution' (Data x y)) | x<-[-10..10], y<-[-10..10]]\n",
    "\n",
    "vlShow $ plot (600, 300)\n",
    "              (L [imagePlot \"x\" \"y\" \"z\"])\n",
    "              (Cols [(\"x\", VL.Numbers ((\\(x, _, _)->x) <$> points1)),\n",
    "                     (\"y\", VL.Numbers ((\\(_, x, _)->x) <$> points1)),\n",
    "                     (\"z\", VL.Numbers ((\\(_, _, x)->x) <$> points1))])\n",
    "-- this plot needs a newer version of jupyterlab and Vega. To see\n",
    "-- the correct version, click on the 3 points in the upper right\n",
    "-- corner and open it in the vega editor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can think about it as a line with some noise around, or as a Gaussian distribution with fixed standard deviation in `y` direction and a mean that increases linearly with `x`, which is closer to the definition.\n",
    "\n",
    "Our statistical model doesn't just describe a single distribution but a different one for each value of `Params`.\n",
    "A bunch of `Params` therefore corresponds to a bunch of sampling distributions.\n",
    "Or, expressed more confusingly, a distribution of `Params` corresponds to a distribution of sampling distributions.\n",
    "Take, for example, a distribution of `Params` that we call `priorParams` where slope, intercept and noise standard deviation are drawn from uniform distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorParams :: MonadSample m => m Params\n",
    "priorParams = do\n",
    "  intercept <- uniform (-5) 5\n",
    "  slope <- uniform (-5) 5\n",
    "  noise <- uniform 1 3\n",
    "  return $ Params slope intercept noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can draw a few parameters from this model parameter distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkSampler = replicateM 9\n",
    "params <- sampleIOfixed $ mkSampler priorParams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compute and plot the corresponding sampling distributions for each parameter sample in the domain `x=[-10, 10]` and `y=[-10, 10]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points2 =\n",
    "  [ [ (iparam, x, y, prob (Data x y))\n",
    "      | x <- [-10, -9.5 .. 10],\n",
    "        y <- [-10, -9.5 .. 10],\n",
    "        let prob = exp . ln . likelihood param\n",
    "    ]\n",
    "    | (iparam, param) <- zip [0 ..] params\n",
    "  ]\n",
    "\n",
    "is = mconcat $ (map . map) (\\(i, _, _, _) -> i) points2\n",
    "xs = mconcat $ (map . map) (\\(_, x, _, _) -> x) points2\n",
    "ys = mconcat $ (map . map) (\\(_, _, y, _) -> y) points2\n",
    "zs = mconcat $ (map . map) (\\(_, _, _, z) -> z) points2\n",
    "\n",
    "vlShow $ plot (600, 300)\n",
    "              (F (\"iParam\", 3, imageFacetPlot \"x\" \"y\" \"likelihood\"))\n",
    "              (Cols [(\"iParam\", VL.Numbers is),\n",
    "                     (\"x\", VL.Numbers xs),\n",
    "                     (\"y\", VL.Numbers ys),\n",
    "                     (\"likelihood\", VL.Numbers zs)])\n",
    "-- this plot needs a newer version of jupyterlab and Vega. To see\n",
    "-- the correct version, click on the 3 points in the upper right\n",
    "-- corner and open it in the vega editor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each distribution varies in terms of its slope, intercept and standard deviation.\n",
    "Note that the maximum of a distribution is lower if it has a higher standard deviation, which is due to the normalized `normalPdf` function we used.\n",
    "However, we didn't properly normalize these distributions within the limited 2D domain but that's not important for what is coming.\n",
    "The important point to understand is that our `likelihood` model describes a family of distributions which are parametrized through `Params`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Data - MCMC\n",
    "\n",
    "Now let's pick one of those distributions, the one with `Params {slope=2.3, intercept=(-1.2), noiseStd=2.0}` that we showed initially, and draw some synthetic data samples from it.\n",
    "\n",
    "To sample with `monad-bayes`, we express `likelihood` directly as a distribution.\n",
    "This means, `likelihood :: Params -> Data -> Log Double` becomes `likelihoodDist :: Params -> m Data`.\n",
    "Here, `m` implements the `MonadInfer` typeclass that represents a distribution from which we can sample.\n",
    "It thus somehow deals with the `Log Double` probability behind the scenes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoodDist :: MonadInfer m => Params -> m Data\n",
    "likelihoodDist params = do\n",
    "  x <- uniform (-10) 10\n",
    "  y <- uniform (-10) 10\n",
    "  score $ likelihood params (Data x y)\n",
    "  return $ Data x y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in our [previous blog post](https://www.tweag.io/posts/2019-09-20-monad-bayes-1.html), we can sample from this distribution with [MCMC](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkSampler = prior . mh 300\n",
    "pointsMCMC <- sampleIOfixed $ mkSampler $ likelihoodDist params0\n",
    "\n",
    "vlShow $ plot (600, 300)\n",
    "              (L [scatterBlue \"x\" \"y\" (-10, 10) (-10, 10)])\n",
    "              (Cols [(\"x\", VL.Numbers (xValue <$> pointsMCMC)), (\"y\", VL.Numbers (yValue <$> pointsMCMC))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did this work?\n",
    "Well, we got some samples, and they are roughly distributed according to the desired distribution that we showed above.\n",
    "But, there is a problem:\n",
    "\n",
    "First, there is an improbable outlier sample all the way on the left.\n",
    "We already blamed this on the initial state of the [Markov chain](https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo) [previously](https://www.tweag.io/posts/2019-09-20-monad-bayes-1.html).\n",
    "We will show you how to skip this initial state later in this post.\n",
    "\n",
    "Then, the samples are not distributed as we would expect.\n",
    "They don't cover the full x-range, which we could fix by pulling more samples with MCMC—but still.\n",
    "And there is a deeper issue, the samples seem to be aligned along the y-axis (and the x-axis if you look closely).\n",
    "The reason is obvious, each sample in the Markov chain (except for the initial one) depends on the previous sample.\n",
    "The distribution of these samples would eventually converge to the one described by `likelihood`, but they are _not independent_.\n",
    "So, we need a different technique here to draw samples that _are independent_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Data - Rejection Sampling\n",
    "\n",
    "Many possible ways exist to draw independent samples from a given distribution, but few approaches are accurate and efficient in any situation.\n",
    "Here we choose an inefficient but quite general approach called [rejection sampling](https://en.wikipedia.org/wiki/Rejection_sampling).\n",
    "It works like this:\n",
    "We first get a bunch of independent uniform 2D data points via `monad-bayes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform2D :: MonadSample m => m Data\n",
    "uniform2D = do\n",
    "  x <- uniform (-10) 10\n",
    "  y <- uniform (-10) 10\n",
    "  return $ Data x y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then draw a list of `2000` points from this distribution with the help of `replicateM` and `sampleIOfixed` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkSampler = replicateM 2000 \n",
    "uniformSamples <- sampleIOfixed $ mkSampler uniform2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These samples aren't distributed according to the desired probability, our sampling distribution, but it is easy to compute it for each of these samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "desiredProb = map samplingDistribution' uniformSamples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can reject unlikely samples and accept the likely ones to get what we want.\n",
    "To decide which ones to accept, we draw a uniform random number for each sample.\n",
    "A sample is only accepted if this number is higher than the desired probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform0 <- sampleIOfixed $ mkSampler $ uniform 0 (maximum desiredProb)\n",
    "points3 = [p | (p, u, l)<-zip3 uniformSamples uniform0 desiredProb, u<l]\n",
    "length points3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rejection procedure removes ~90% of all uniformly distributed points and reduces the initial number of `2000` points to only `190`.\n",
    "But the probability to accept is proportional to the desired probability.\n",
    "The remaining points are therefore independent and distributed according to our desired sampling distribution, as this plot demonstrates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlShow $ plot (600, 300)\n",
    "              (L [scatterBlue \"x\" \"y\" (-10, 10) (-10, 10)])\n",
    "              (Cols [(\"x\", VL.Numbers (xValue <$> points3)), (\"y\", VL.Numbers (yValue <$> points3))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rejection sampling is often not very efficient, but it is simple and straight forward.\n",
    "By design, most rejected samples are in low probability regions, and it is thus crucial to choose an initial distribution that is concentrated around high probability regions—if we know where they are.\n",
    "Long story short, we now have data samples that correspond to the sampling distribution identified by `Params {slope=2.3, intercept=(-1.2), noiseStd=2.0}`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression - Inferring Slope and Intercept\n",
    "\n",
    "Can we find the parameters that we have used from the data points only?\n",
    "In other words, can we find the _specific_ distribution that generated the data points from the _family_ of distributions that our model describes?\n",
    "Well, at least we can assess how probable it is that a distribution in the model generates the data - the likelihood.\n",
    "With this likelihood, we can score the distributions from the prior distribution of parameters `priorParams` that we have defined before.\n",
    "Now pay attention, here is the inference recipe, in English and in Haskell:\n",
    "\n",
    "_pull out a model parameter sample from the prior distribution and score it with the likelihood to observe all data points_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postParams :: MonadInfer m => m Params -> [Data] -> m Params\n",
    "postParams pr obs = do\n",
    "  param <- pr\n",
    "  forM_ obs (\\point -> score (likelihood param point))\n",
    "  return param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, the `score` function multiplies the relative probability of a model parameter sample with a factor:\n",
    "Our belief in model parameters that correspond to distributions that _likely_ generate what we observe are multiplied with a _high_ number.\n",
    "Our belief in model parameters that correspond to distributions that are _unlikely_ to generate what we observe are multiplied with a _low_ number.\n",
    "We thus update the prior probabilities of model parameters and get a new posterior distribution of model parameters.\n",
    "\n",
    "But now the question is again how we can sample from this posterior distribution.\n",
    "The sampler that we use to handle the `score` operation, that is updating relative probabilities of samples in a distribution, is [Metropolis-Hastings](https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkSampler = prior . mh 1000\n",
    "modelsamples <- sampleIOfixed $ mkSampler $ postParams priorParams points3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how the posterior distribution looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stable = take 800 modelsamples\n",
    "vlShow $ plot (600, 300)\n",
    "              (L [density2DPlot \"intercept\" \"slope\" (-5, 5) (-5, 5)])\n",
    "              (Cols [(\"intercept\", VL.Numbers (intercept <$> stable)), (\"slope\", VL.Numbers (slope <$> stable))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This posterior distribution over model parameters describes how likely each sampling distribution in the model generates the observed data.\n",
    "It peaks at an intercept of `-1.5` - `-1` (the actual value was `-1.2`) and a slope of `1.5`-`2.5` (the actual value was `2.3`).\n",
    "It seems to work, although we should have probably sampled a bit more to make this more accurate.\n",
    "\n",
    "You might have noticed that we only use 800/1000 samples here (`take 800` in the code snippet above).\n",
    "What is the reason? \n",
    "If you remember, we saw some random initial samples of the Markov chain in the posterior model parameter distribution in our [last post](https://www.tweag.io/posts/2019-09-20-monad-bayes-1.html).\n",
    "This was because the chain starts at a random position and needs some steps to reach the stable equilibrium that describes the posterior distribution.\n",
    "We therefore skip the initial part of it.\n",
    "Why do we use `take` rather than `drop` for this?\n",
    "Samples are by default appended at the beginning of the list.\n",
    "Therefore, `take 800` means that we use the `800` latest samples of the chain and drop the `200` initial ones.\n",
    "Want to know why we skipped 200 and not 20 points? Check out the Appendix for more details!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating Data\n",
    "\n",
    "The posterior distribution of the model parameters tells us which distributions likely generate the observed data.\n",
    "What data would we generate from the sampling distributions defined by this posterior distribution?\n",
    "\n",
    "Let's write a new sampler for a _predictive distribution_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predDist :: MonadInfer m => m Params -> m Data\n",
    "predDist paramDist = do\n",
    "  params <- paramDist\n",
    "  point <- likelihoodDist params\n",
    "  return point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We draw samples from it with Metropolis-Hastings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkSampler = prior . mh 40000 \n",
    "pts <- sampleIOfixed $  mkSampler $ predDist $ postParams priorParams points3\n",
    "predPoints = take (length pts - 100) pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vlShow $ plot (600, 300)\n",
    "              (L [density2DPlot \"x2\" \"y2\" (-10, 10) (-10, 10), scatterGreen \"x\" \"y\" (-10, 10) (-10, 10)])\n",
    "              (Cols [(\"x\", VL.Numbers (xValue <$> points3)), (\"y\", VL.Numbers (yValue <$> points3)),\n",
    "                     (\"x2\", VL.Numbers (xValue <$> predPoints)), (\"y2\", VL.Numbers (yValue <$> predPoints))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks quite OK; the simulated distribution (blue) looks similar to the original data (green).\n",
    "Although we have drawn 40000 samples with MCMC, you see that the distribution is still not as smooth and nice as we would expect.\n",
    "Of course, we could sample more, but we really should think about our sampling method and see how we adapt it to the problem and make it more efficient.\n",
    "But, that's not the aim of this post, so we'll postpone that discussion to later in our series.\n",
    "\n",
    "Note that `predDist` looks _very_ similar to `likelihoodDist`.\n",
    "The fundamental difference is that the former takes a distribution, in this case the _posterior predictive_ distribution `postParams priorParams points :: m Params` as input, whereas the latter accepts a single value, in this case `params :: Params`.\n",
    "The resulting distributions, that we are comparing in the plot above, `likelihoodDist params` and `predDist (postParams priorParams points)` look similar—and it is fairly obvious why:\n",
    "The posterior predictive distribution peaks at values close to `params` and is zero elsewhere.\n",
    "Why does it peak at these values?\n",
    "Well, we gave a high score to those model parameters that are likely to produce the same data as `params0`.\n",
    "This explanation becomes somewhat circular, but it illustrates again _why_ the predicted points look like the ones that we used for fitting by design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "We went step by step through the modeling process with `monad-bayes` and a linear regression example.\n",
    "We learned that the model setup takes only a few lines of code, that is the implementation of `Data`, `Params`, and `likelihood` plus the definition of `prior` and `posterior`.\n",
    "With these initial definitions, the composability of Haskell functions allows us to rapidly get new distributions like `samplingDistribution` or a `predDist`.\n",
    "Involved and with big implications is the sampling process, the choice of the sampling technique, and how it is adapted to the current situation.\n",
    "To sample, we used Metropolis-Hastings and rejection sampling but many other sampling strategies exist.\n",
    "\n",
    "We hope you enjoyed this second post in our Probabilistic Programming with monad‑bayes Series and learned lots! A central aspect of `monad-bayes` is to enable the modeller to use and compose different sampling techniques for their models. Now, you're ready to start getting into such questions in our next post. We hope you join us!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix - Stability of the Monte Carlo chain\n",
    "\n",
    "The Markov chain, that we used to sample in this blog post, is a stochastic process that cycles through possible models.\n",
    "Models that are more likely are hit more often than models that are less likely, and over time we thus recover the model distribution that we are interested in.\n",
    "However, typically it needs a while to reach the unique stationary distribution that is equal to the model distribution distribution.\n",
    "A simple way to assess when it becomes stationary is to look at the likelihood that it reaches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihoods = [Numeric.Log.sum (map prob points3) | param <- modelsamples, let prob = likelihood param]\n",
    "nsamples = length likelihoods\n",
    "\n",
    "vlShow $ plot (600, 300)\n",
    "              (L [linePlot \"imodel\" \"likelihood\"])\n",
    "              (Cols [(\"imodel\", VL.Numbers $ fromIntegral <$> [nsamples, nsamples-1..0]), (\"likelihood\", VL.Numbers (ln <$> likelihoods))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our MC chain is non-stationary in the beginning at `imodel` values up to 100, and then reaches stationary behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "We use [this GitHub version](https://github.com/adscib/monad-bayes/tree/f55d9fa9d24d169d53bb03598306ee8c46b5fc11) of`monad-bayes`in our posts and notebooks since it's neither on Hackage nor Stackage right now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Haskell - bayes-monad",
   "language": "haskell",
   "name": "ihaskell_bayes-monad"
  },
  "language_info": {
   "codemirror_mode": "ihaskell",
   "file_extension": ".hs",
   "name": "haskell",
   "pygments_lexer": "Haskell",
   "version": "8.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
